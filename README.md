# ASL Translator
## Overview 
American sign language is used across the globe for a variety of reasons. People use this method of communication to communicate with those that cannot communicate in a traditional manner. Although useful, ASL can be difficult and time consuming to learn. A2T attempts to bridge the gap between those that can sign and those that cannot. A2T uses deep learning technologies specifically, a Convolution Neural Network, to image recognize, process, and classify to return the text out of the image input provided into the web application. The algorithm is trained on 87,000 photos from a dataset that contains all letters of the alphabet and 3 extra characters. The model is then deployed to a web application for public use. Recommendations for future studies suggest an adaptation of a more powerful algorithm and increase in processing power to increase model performance and accuracy.  
## Technology Stack
1. ReactJS
2. TensorFlow and TensorFlow.js
3. Keras 
4. Python 
## Diagram 
![Image description](https://github.com/pddang/asl-interpreter/blob/master/_Composite%20Diagram-Detailed%20(1).png)
